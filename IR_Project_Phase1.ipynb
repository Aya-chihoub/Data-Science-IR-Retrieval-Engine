{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Science Project: Information Retrieval Engine\n",
        "## Phase 1: Retrieval Basics\n",
        "\n",
        "**Team Members:** Yannis Hemdane, Rayan Khatim, Nour el imene Khelassi, Aya Chihoub\n",
        "\n",
        "**Phase 1 Deadline:** March 2, 2026, 11:59 PM\n",
        "\n",
        "---\n",
        "\n",
        "### Table of Contents\n",
        "1. [Setup & Imports](#1-setup--imports)\n",
        "2. [Data Loading & Preparation](#2-data-loading--preparation)\n",
        "3. [Data Analysis & Statistics](#3-data-analysis--statistics)\n",
        "4. [Retrieval Methods](#4-retrieval-methods)\n",
        "   - 4.1 TF-IDF Retrieval\n",
        "   - 4.2 BM25+ Retrieval\n",
        "   - 4.3 Text Embeddings (SentenceTransformers)\n",
        "5. [Visualization](#5-visualization)\n",
        "6. [Evaluation Suite](#6-evaluation-suite)\n",
        "7. [Results Comparison](#7-results-comparison)\n",
        "8. [Kaggle Submission](#8-kaggle-submission)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
            "[notice] To update, run: C:\\Users\\DELL\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install pandas numpy scikit-learn rank_bm25 sentence-transformers umap-learn matplotlib seaborn tqdm -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\DELL\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "\n",
        "# Retrieval methods\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rank_bm25 import BM25Plus\n",
        "\n",
        "# Embeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "try:\n",
        "    import umap\n",
        "    UMAP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    UMAP_AVAILABLE = False\n",
        "\n",
        "# Progress bars\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Settings\n",
        "pd.set_option('display.max_colwidth', 100)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Data Loading & Preparation\n",
        "\n",
        "The dataset consists of:\n",
        "- **Documents (docs.json)**: The document collection with id, title, text, tags, and category\n",
        "- **Training Queries (queries_train.json)**: Queries for evaluation\n",
        "- **Test Queries (queries_test.json)**: Queries for Kaggle submission\n",
        "- **Ground Truth (qgts_train.json)**: Relevant document IDs for each training query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Data loaded successfully!\n",
            "   Documents: 216,041\n",
            "   Training Queries: 327\n",
            "   Test Queries: 141\n",
            "   Ground Truth entries: 327\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# IMPORTANT: Download data from Kaggle first!\n",
        "# ============================================================\n",
        "# 1. Go to: https://www.kaggle.com/t/f383bc6c1f194226bb43d21ab3d65418\n",
        "# 2. Download and extract the dataset files to the 'data/' folder:\n",
        "#    - docs.json\n",
        "#    - queries_train.json  \n",
        "#    - queries_test.json\n",
        "#    - qgts_train.json\n",
        "# ============================================================\n",
        "\n",
        "DATA_DIR = Path('data/retrieval-engine-competition')\n",
        "\n",
        "# Check if data files exist\n",
        "required_files = ['docs.json', 'queries_train.json', 'queries_test.json', 'qgts_train.json']\n",
        "missing = [f for f in required_files if not (DATA_DIR / f).exists()]\n",
        "\n",
        "if missing:\n",
        "    print(\"‚ùå Missing data files in 'data/' folder:\")\n",
        "    for f in missing:\n",
        "        print(f\"   - {f}\")\n",
        "    print(\"\\nüì• Please download from Kaggle:\")\n",
        "    print(\"   https://www.kaggle.com/t/f383bc6c1f194226bb43d21ab3d65418\")\n",
        "else:\n",
        "    # Load the data\n",
        "    df_docs = pd.read_json(DATA_DIR / 'docs.json')\n",
        "    df_queries_train = pd.read_json(DATA_DIR / 'queries_train.json')\n",
        "    df_queries_test = pd.read_json(DATA_DIR / 'queries_test.json')\n",
        "\n",
        "    with open(DATA_DIR / 'qgts_train.json', 'r') as f:\n",
        "        ground_truth = json.load(f)\n",
        "\n",
        "    print(f\"‚úÖ Data loaded successfully!\")\n",
        "    print(f\"   Documents: {len(df_docs):,}\")\n",
        "    print(f\"   Training Queries: {len(df_queries_train):,}\")\n",
        "    print(f\"   Test Queries: {len(df_queries_test):,}\")\n",
        "    print(f\"   Ground Truth entries: {len(ground_truth):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÑ Sample Document:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6970cbf2-ffff-4c7b-b73d-52524000c232_145427</td>\n",
              "      <td>I try to install Complete MiKTeX 2.9 But there is this: Error: The operation could not be comple...</td>\n",
              "      <td>MikTex Download Failure - toptesi.tar.lzma</td>\n",
              "      <td>[miktex]</td>\n",
              "      <td>tex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>667220d0-66be-4059-ae60-b9df15d285f7_77850</td>\n",
              "      <td>I'm trying to get a launcher working for the WikidPad (python) program.   I already have a pytho...</td>\n",
              "      <td>Launcher for a Python program that requires extra libraries</td>\n",
              "      <td>[gnome3, python, path, cd]</td>\n",
              "      <td>unix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            id  \\\n",
              "0  6970cbf2-ffff-4c7b-b73d-52524000c232_145427   \n",
              "1   667220d0-66be-4059-ae60-b9df15d285f7_77850   \n",
              "\n",
              "                                                                                                  text  \\\n",
              "0  I try to install Complete MiKTeX 2.9 But there is this: Error: The operation could not be comple...   \n",
              "1  I'm trying to get a launcher working for the WikidPad (python) program.   I already have a pytho...   \n",
              "\n",
              "                                                         title  \\\n",
              "0                   MikTex Download Failure - toptesi.tar.lzma   \n",
              "1  Launcher for a Python program that requires extra libraries   \n",
              "\n",
              "                         tags category  \n",
              "0                    [miktex]      tex  \n",
              "1  [gnome3, python, path, cd]     unix  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚ùì Sample Query:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>title</th>\n",
              "      <th>tags</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>961c4349-8cf1-4ef1-89cc-24d20bb9d000_67878</td>\n",
              "      <td>Want to try reformatting Damaged SD Card</td>\n",
              "      <td></td>\n",
              "      <td>[linux, development]</td>\n",
              "      <td>android</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4008ed78-e66e-4d89-9c3b-c79bd1cf6fc9_366</td>\n",
              "      <td>Convince grep to output all lines, not just those with matches</td>\n",
              "      <td></td>\n",
              "      <td>[shell, virtualization, storage, cluster]</td>\n",
              "      <td>unix</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           id  \\\n",
              "0  961c4349-8cf1-4ef1-89cc-24d20bb9d000_67878   \n",
              "1    4008ed78-e66e-4d89-9c3b-c79bd1cf6fc9_366   \n",
              "\n",
              "                                                             text title  \\\n",
              "0                        Want to try reformatting Damaged SD Card         \n",
              "1  Convince grep to output all lines, not just those with matches         \n",
              "\n",
              "                                        tags category  \n",
              "0                       [linux, development]  android  \n",
              "1  [shell, virtualization, storage, cluster]     unix  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Preview the data\n",
        "print(\"üìÑ Sample Document:\")\n",
        "display(df_docs.head(2))\n",
        "\n",
        "print(\"\\n‚ùì Sample Query:\")\n",
        "display(df_queries_train.head(2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1 Text Preprocessing\n",
        "\n",
        "We create a unified `content` field by merging title, text, and tags. This gives the retrieval models more context to work with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing documents...\n",
            "Processing training queries...\n",
            "Processing test queries...\n",
            "‚úÖ Text preprocessing complete!\n"
          ]
        }
      ],
      "source": [
        "def merge_fields(row):\n",
        "    \"\"\"Combine title, text, and tags into a single content field.\"\"\"\n",
        "    title = str(row.get('title', '') or '')\n",
        "    text = str(row.get('text', '') or '')\n",
        "    tags_list = row.get('tags', [])\n",
        "    tags = \" \".join(tags_list) if isinstance(tags_list, list) else \"\"\n",
        "    \n",
        "    combined = f\"{title} {text} {tags}\"\n",
        "    return \" \".join(combined.split())  # Normalize whitespace\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean text: lowercase and remove punctuation.\"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "print(\"Processing documents...\")\n",
        "df_docs['content'] = df_docs.apply(merge_fields, axis=1)\n",
        "df_docs['content_clean'] = df_docs['content'].apply(clean_text)\n",
        "\n",
        "print(\"Processing training queries...\")\n",
        "df_queries_train['content'] = df_queries_train.apply(merge_fields, axis=1)\n",
        "df_queries_train['content_clean'] = df_queries_train['content'].apply(clean_text)\n",
        "\n",
        "print(\"Processing test queries...\")\n",
        "df_queries_test['content'] = df_queries_test.apply(merge_fields, axis=1)\n",
        "df_queries_test['content_clean'] = df_queries_test['content'].apply(clean_text)\n",
        "\n",
        "print(\"‚úÖ Text preprocessing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Data Analysis & Statistics\n",
        "\n",
        "Before building our retrieval system, let's understand our dataset better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "üìä DATASET STATISTICS\n",
            "============================================================\n",
            "\n",
            "üìÑ DOCUMENTS:\n",
            "   Total documents: 216,041\n",
            "   Columns: ['id', 'text', 'title', 'tags', 'category', 'content', 'content_clean']\n",
            "\n",
            "‚ùì QUERIES:\n",
            "   Training queries: 327\n",
            "   Test queries: 141\n",
            "\n",
            "üéØ RELEVANCE JUDGMENTS:\n",
            "   Total relevance judgments: 981\n",
            "   Average relevant docs per query: 3.00\n"
          ]
        }
      ],
      "source": [
        "# Basic statistics\n",
        "print(\"=\"*60)\n",
        "print(\"üìä DATASET STATISTICS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"\\nüìÑ DOCUMENTS:\")\n",
        "print(f\"   Total documents: {len(df_docs):,}\")\n",
        "print(f\"   Columns: {list(df_docs.columns)}\")\n",
        "\n",
        "print(f\"\\n‚ùì QUERIES:\")\n",
        "print(f\"   Training queries: {len(df_queries_train):,}\")\n",
        "print(f\"   Test queries: {len(df_queries_test):,}\")\n",
        "\n",
        "print(f\"\\nüéØ RELEVANCE JUDGMENTS:\")\n",
        "total_relevant = sum(len(v) for v in ground_truth.values())\n",
        "avg_relevant = total_relevant / len(ground_truth)\n",
        "print(f\"   Total relevance judgments: {total_relevant:,}\")\n",
        "print(f\"   Average relevant docs per query: {avg_relevant:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìè CONTENT LENGTH STATISTICS:\n",
            "\n",
            "Documents:\n",
            "count    216041.000000\n",
            "mean        137.182234\n",
            "std         146.971431\n",
            "min           9.000000\n",
            "25%          64.000000\n",
            "50%         100.000000\n",
            "75%         161.000000\n",
            "max        5256.000000\n",
            "Name: content_length, dtype: float64\n",
            "\n",
            "Queries:\n",
            "count    327.000000\n",
            "mean      11.437309\n",
            "std        3.902361\n",
            "min        3.000000\n",
            "25%        9.000000\n",
            "50%       11.000000\n",
            "75%       13.000000\n",
            "max       31.000000\n",
            "Name: content_length, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Document length statistics\n",
        "df_docs['content_length'] = df_docs['content'].str.split().str.len()\n",
        "df_queries_train['content_length'] = df_queries_train['content'].str.split().str.len()\n",
        "\n",
        "print(\"\\nüìè CONTENT LENGTH STATISTICS:\")\n",
        "print(\"\\nDocuments:\")\n",
        "print(df_docs['content_length'].describe())\n",
        "\n",
        "print(\"\\nQueries:\")\n",
        "print(df_queries_train['content_length'].describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÇ CATEGORY DISTRIBUTION:\n",
            "category\n",
            "tex            68184\n",
            "unix           47382\n",
            "gaming         45301\n",
            "programmers    32176\n",
            "android        22998\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Category distribution (if available)\n",
        "if 'category' in df_docs.columns:\n",
        "    print(\"\\nüìÇ CATEGORY DISTRIBUTION:\")\n",
        "    category_counts = df_docs['category'].value_counts()\n",
        "    print(category_counts)\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    category_counts.plot(kind='bar', ax=ax, color='steelblue')\n",
        "    ax.set_title('Document Category Distribution')\n",
        "    ax.set_xlabel('Category')\n",
        "    ax.set_ylabel('Count')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('reports/category_distribution.png', dpi=150)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Retrieval Methods\n",
        "\n",
        "We implement three retrieval methods:\n",
        "1. **TF-IDF** - Term Frequency-Inverse Document Frequency\n",
        "2. **BM25+** - Best Matching 25 Plus\n",
        "3. **Text Embeddings** - Using SentenceTransformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 TF-IDF Retrieval\n",
        "\n",
        "**How TF-IDF works:**\n",
        "\n",
        "TF-IDF (Term Frequency-Inverse Document Frequency) is a statistical measure that evaluates how important a word is to a document in a collection.\n",
        "\n",
        "- **TF (Term Frequency)**: How often a word appears in a document. More occurrences = higher importance.\n",
        "- **IDF (Inverse Document Frequency)**: How rare a word is across all documents. Rare words get higher scores.\n",
        "\n",
        "$$\\text{TF-IDF}(t, d) = \\text{TF}(t, d) \\times \\log\\left(\\frac{N}{\\text{DF}(t)}\\right)$$\n",
        "\n",
        "Where:\n",
        "- $t$ = term, $d$ = document, $N$ = total documents, $\\text{DF}(t)$ = documents containing term $t$\n",
        "\n",
        "We use **cosine similarity** to compare query and document vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building TF-IDF model...\n",
            "TF-IDF Document Matrix Shape: (216041, 100000)\n",
            "TF-IDF Query Matrix Shape: (327, 100000)\n"
          ]
        }
      ],
      "source": [
        "# TF-IDF Retrieval\n",
        "print(\"Building TF-IDF model...\")\n",
        "\n",
        "# Initialize vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=100000)\n",
        "\n",
        "# Fit on documents\n",
        "tfidf_doc_matrix = tfidf_vectorizer.fit_transform(df_docs['content_clean'])\n",
        "print(f\"TF-IDF Document Matrix Shape: {tfidf_doc_matrix.shape}\")\n",
        "\n",
        "# Transform queries\n",
        "tfidf_query_matrix = tfidf_vectorizer.transform(df_queries_train['content_clean'])\n",
        "print(f\"TF-IDF Query Matrix Shape: {tfidf_query_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "TF-IDF Retrieval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 327/327 [00:01<00:00, 189.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ TF-IDF retrieval complete!\n",
            "Sample result for query 0: ['cbac6e51-ea52-4824-be99-93db1abbe35a_62218', '6260dea3-8a5e-4e28-8c8e-9340f9352887_23121', 'a1fdd2bb-79eb-4dc5-8671-afca8cd3dac3_44409']...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def retrieve_topk_tfidf(query_matrix, doc_matrix, doc_ids, k=10):\n",
        "    \"\"\"Retrieve top-k documents for each query using TF-IDF + cosine similarity.\"\"\"\n",
        "    topk_indices = []\n",
        "    topk_scores = []\n",
        "    \n",
        "    # Compute similarities\n",
        "    similarities = cosine_similarity(query_matrix, doc_matrix)\n",
        "    \n",
        "    for i in tqdm(range(similarities.shape[0]), desc=\"TF-IDF Retrieval\"):\n",
        "        scores = similarities[i]\n",
        "        top_idx = np.argsort(scores)[-k:][::-1]\n",
        "        \n",
        "        topk_indices.append([doc_ids[j] for j in top_idx])\n",
        "        topk_scores.append(scores[top_idx].tolist())\n",
        "    \n",
        "    return topk_indices, topk_scores\n",
        "\n",
        "# Retrieve\n",
        "K = 10\n",
        "doc_ids = df_docs['id'].tolist()\n",
        "\n",
        "topk_indices_tfidf, topk_scores_tfidf = retrieve_topk_tfidf(\n",
        "    tfidf_query_matrix, tfidf_doc_matrix, doc_ids, k=K\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ TF-IDF retrieval complete!\")\n",
        "print(f\"Sample result for query 0: {topk_indices_tfidf[0][:3]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 BM25+ Retrieval\n",
        "\n",
        "**How BM25+ works:**\n",
        "\n",
        "BM25+ is a ranking function used by search engines. It improves on TF-IDF by:\n",
        "- Adding **saturation**: Term frequency impact diminishes for very frequent terms\n",
        "- **Document length normalization**: Prevents bias towards longer documents\n",
        "- **+** variant adds a small constant to prevent zero scores\n",
        "\n",
        "$$\\text{BM25+}(q, d) = \\sum_{t \\in q} \\text{IDF}(t) \\cdot \\frac{f(t, d) \\cdot (k_1 + 1)}{f(t, d) + k_1 \\cdot (1 - b + b \\cdot \\frac{|d|}{\\text{avgdl}})} + \\delta$$\n",
        "\n",
        "Parameters:\n",
        "- $k_1$ (typically 1.2-2.0): Controls term frequency saturation\n",
        "- $b$ (typically 0.75): Controls document length normalization\n",
        "- $\\delta$ (typically 1): Lower bound for term weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building BM25+ model...\n",
            "‚úÖ BM25+ model built on 216,041 documents\n"
          ]
        }
      ],
      "source": [
        "# BM25+ Retrieval\n",
        "print(\"Building BM25+ model...\")\n",
        "\n",
        "# Tokenize corpus\n",
        "tokenized_corpus = [doc.split() for doc in df_docs['content_clean']]\n",
        "\n",
        "# Initialize BM25+\n",
        "bm25_model = BM25Plus(tokenized_corpus)\n",
        "\n",
        "print(f\"‚úÖ BM25+ model built on {len(tokenized_corpus):,} documents\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BM25+ Retrieval: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 327/327 [04:28<00:00,  1.22it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ BM25+ retrieval complete!\n",
            "Sample result for query 0: ['276bf1e2-20da-4758-9009-d2472ad21266_17022', '6260dea3-8a5e-4e28-8c8e-9340f9352887_23121', 'a1fdd2bb-79eb-4dc5-8671-afca8cd3dac3_44409']...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def retrieve_topk_bm25(queries, bm25, doc_ids, k=10):\n",
        "    \"\"\"Retrieve top-k documents for each query using BM25+.\"\"\"\n",
        "    topk_indices = []\n",
        "    topk_scores = []\n",
        "    \n",
        "    for query in tqdm(queries, desc=\"BM25+ Retrieval\"):\n",
        "        tokenized_query = query.split()\n",
        "        scores = bm25.get_scores(tokenized_query)\n",
        "        \n",
        "        top_idx = np.argsort(scores)[-k:][::-1]\n",
        "        \n",
        "        topk_indices.append([doc_ids[j] for j in top_idx])\n",
        "        topk_scores.append(scores[top_idx].tolist())\n",
        "    \n",
        "    return topk_indices, topk_scores\n",
        "\n",
        "# Retrieve\n",
        "topk_indices_bm25, topk_scores_bm25 = retrieve_topk_bm25(\n",
        "    df_queries_train['content_clean'].tolist(), bm25_model, doc_ids, k=K\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ BM25+ retrieval complete!\")\n",
        "print(f\"Sample result for query 0: {topk_indices_bm25[0][:3]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Text Embeddings (SentenceTransformers)\n",
        "\n",
        "**What are embeddings and why use them?**\n",
        "\n",
        "Text embeddings are dense vector representations that capture the **semantic meaning** of text. Unlike TF-IDF/BM25 which rely on exact word matching, embeddings can:\n",
        "\n",
        "1. **Understand synonyms**: \"car\" and \"automobile\" have similar embeddings\n",
        "2. **Capture context**: \"bank\" (financial) vs \"bank\" (river) get different representations\n",
        "3. **Handle paraphrases**: Different phrasings of the same idea are close in vector space\n",
        "\n",
        "We use **SentenceTransformers** which are pre-trained models specifically designed for semantic similarity tasks.\n",
        "\n",
        "**Model**: `all-MiniLM-L6-v2` - A good balance of speed and quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading SentenceTransformer model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 580.84it/s, Materializing param=pooler.dense.weight]                             \n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Model loaded!\n",
            "   Embedding dimension: 384\n"
          ]
        }
      ],
      "source": [
        "# Load SentenceTransformer model\n",
        "print(\"Loading SentenceTransformer model...\")\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "print(f\"‚úÖ Model loaded!\")\n",
        "print(f\"   Embedding dimension: {embedding_model.get_sentence_embedding_dimension()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating document embeddings...\n",
            "‚ö†Ô∏è This may take several minutes for large datasets. Consider using GPU.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches:  27%|‚ñà‚ñà‚ñã       | 906/3376 [1:16:47<3:29:21,  5.09s/it] \n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è This may take several minutes for large datasets. Consider using GPU.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Use original content (not cleaned) for better semantic understanding\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m doc_embeddings = \u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdf_docs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\n\u001b[32m     10\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Document embeddings shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_embeddings.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\utils\\_contextlib.py:124\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# pyrefly: ignore [bad-context-manager]\u001b[39;00m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sentence_transformers\\models\\Transformer.py:262\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    264\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\utils\\generic.py:1002\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m             outputs = func(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m   1001\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m         outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1004\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1005\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1006\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1007\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\models\\bert\\modeling_bert.py:696\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    679\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m    680\u001b[39m     input_ids=input_ids,\n\u001b[32m    681\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    684\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m    685\u001b[39m )\n\u001b[32m    687\u001b[39m attention_mask, encoder_attention_mask = \u001b[38;5;28mself\u001b[39m._create_attention_masks(\n\u001b[32m    688\u001b[39m     attention_mask=attention_mask,\n\u001b[32m    689\u001b[39m     encoder_attention_mask=encoder_attention_mask,\n\u001b[32m   (...)\u001b[39m\u001b[32m    693\u001b[39m     past_key_values=past_key_values,\n\u001b[32m    694\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m696\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m sequence_output = encoder_outputs.last_hidden_state\n\u001b[32m    708\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\models\\bert\\modeling_bert.py:452\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    442\u001b[39m     hidden_states: torch.Tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m    449\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    450\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[torch.Tensor] | BaseModelOutputWithPastAndCrossAttentions:\n\u001b[32m    451\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, layer_module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.layer):\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m         hidden_states = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    456\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPastAndCrossAttentions(\n\u001b[32m    463\u001b[39m         last_hidden_state=hidden_states,\n\u001b[32m    464\u001b[39m         past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    465\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\modeling_layers.py:93\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m         logger.warning_once(message)\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\models\\bert\\modeling_bert.py:423\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    413\u001b[39m     cross_attention_output, _ = \u001b[38;5;28mself\u001b[39m.crossattention(\n\u001b[32m    414\u001b[39m         self_attention_output,\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# attention_mask\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    419\u001b[39m         **kwargs,\n\u001b[32m    420\u001b[39m     )\n\u001b[32m    421\u001b[39m     attention_output = cross_attention_output\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\pytorch_utils.py:201\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    198\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\models\\bert\\modeling_bert.py:429\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\transformers\\models\\bert\\modeling_bert.py:348\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    350\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\torch\\nn\\modules\\linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Generate document embeddings (this may take a while for large datasets)\n",
        "print(\"Generating document embeddings...\")\n",
        "print(\"‚ö†Ô∏è This may take several minutes for large datasets. Consider using GPU.\")\n",
        "\n",
        "# Use original content (not cleaned) for better semantic understanding\n",
        "doc_embeddings = embedding_model.encode(\n",
        "    df_docs['content'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Document embeddings shape: {doc_embeddings.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate query embeddings\n",
        "print(\"Generating query embeddings...\")\n",
        "\n",
        "query_embeddings_train = embedding_model.encode(\n",
        "    df_queries_train['content'].tolist(),\n",
        "    show_progress_bar=True,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Query embeddings shape: {query_embeddings_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retrieve_topk_embeddings(query_emb, doc_emb, doc_ids, k=10):\n",
        "    \"\"\"Retrieve top-k documents using embedding similarity.\"\"\"\n",
        "    topk_indices = []\n",
        "    topk_scores = []\n",
        "    \n",
        "    # Compute cosine similarities\n",
        "    similarities = cosine_similarity(query_emb, doc_emb)\n",
        "    \n",
        "    for i in tqdm(range(len(query_emb)), desc=\"Embedding Retrieval\"):\n",
        "        scores = similarities[i]\n",
        "        top_idx = np.argsort(scores)[-k:][::-1]\n",
        "        \n",
        "        topk_indices.append([doc_ids[j] for j in top_idx])\n",
        "        topk_scores.append(scores[top_idx].tolist())\n",
        "    \n",
        "    return topk_indices, topk_scores\n",
        "\n",
        "# Retrieve\n",
        "topk_indices_emb, topk_scores_emb = retrieve_topk_embeddings(\n",
        "    query_embeddings_train, doc_embeddings, doc_ids, k=K\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Embedding retrieval complete!\")\n",
        "print(f\"Sample result for query 0: {topk_indices_emb[0][:3]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Visualization\n",
        "\n",
        "We use dimensionality reduction (t-SNE or UMAP) to visualize our embeddings in 2D and analyze category clustering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample embeddings for visualization (full dataset would be too slow)\n",
        "SAMPLE_SIZE = 5000\n",
        "\n",
        "# Random sample\n",
        "np.random.seed(42)\n",
        "sample_idx = np.random.choice(len(doc_embeddings), min(SAMPLE_SIZE, len(doc_embeddings)), replace=False)\n",
        "\n",
        "sample_embeddings = doc_embeddings[sample_idx]\n",
        "sample_categories = df_docs.iloc[sample_idx]['category'].values if 'category' in df_docs.columns else None\n",
        "\n",
        "print(f\"Sampled {len(sample_embeddings)} documents for visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# t-SNE visualization\n",
        "print(\"Running t-SNE dimensionality reduction...\")\n",
        "print(\"‚ö†Ô∏è This may take a few minutes...\")\n",
        "\n",
        "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
        "embeddings_2d_tsne = tsne.fit_transform(sample_embeddings)\n",
        "\n",
        "print(f\"‚úÖ t-SNE complete! Output shape: {embeddings_2d_tsne.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot t-SNE results\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "if sample_categories is not None:\n",
        "    # Color by category\n",
        "    unique_cats = np.unique(sample_categories)\n",
        "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_cats)))\n",
        "    \n",
        "    for i, cat in enumerate(unique_cats):\n",
        "        mask = sample_categories == cat\n",
        "        ax.scatter(\n",
        "            embeddings_2d_tsne[mask, 0],\n",
        "            embeddings_2d_tsne[mask, 1],\n",
        "            c=[colors[i]],\n",
        "            label=cat,\n",
        "            alpha=0.6,\n",
        "            s=10\n",
        "        )\n",
        "    ax.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "else:\n",
        "    ax.scatter(embeddings_2d_tsne[:, 0], embeddings_2d_tsne[:, 1], alpha=0.6, s=10)\n",
        "\n",
        "ax.set_title('t-SNE Visualization of Document Embeddings')\n",
        "ax.set_xlabel('t-SNE Dimension 1')\n",
        "ax.set_ylabel('t-SNE Dimension 2')\n",
        "plt.tight_layout()\n",
        "plt.savefig('reports/tsne_visualization.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UMAP visualization (if available - often faster and better for large datasets)\n",
        "if UMAP_AVAILABLE:\n",
        "    print(\"Running UMAP dimensionality reduction...\")\n",
        "    \n",
        "    reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=15, min_dist=0.1)\n",
        "    embeddings_2d_umap = reducer.fit_transform(sample_embeddings)\n",
        "    \n",
        "    # Plot\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    \n",
        "    if sample_categories is not None:\n",
        "        for i, cat in enumerate(unique_cats):\n",
        "            mask = sample_categories == cat\n",
        "            ax.scatter(\n",
        "                embeddings_2d_umap[mask, 0],\n",
        "                embeddings_2d_umap[mask, 1],\n",
        "                c=[colors[i]],\n",
        "                label=cat,\n",
        "                alpha=0.6,\n",
        "                s=10\n",
        "            )\n",
        "        ax.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    else:\n",
        "        ax.scatter(embeddings_2d_umap[:, 0], embeddings_2d_umap[:, 1], alpha=0.6, s=10)\n",
        "    \n",
        "    ax.set_title('UMAP Visualization of Document Embeddings')\n",
        "    ax.set_xlabel('UMAP Dimension 1')\n",
        "    ax.set_ylabel('UMAP Dimension 2')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('reports/umap_visualization.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"UMAP not available. Install with: pip install umap-learn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualization Analysis\n",
        "\n",
        "**Observations:**\n",
        "\n",
        "*[Answer the following based on your visualizations:]*\n",
        "\n",
        "1. **Do you notice any clustering?** \n",
        "   - *TODO: Describe whether documents form distinct clusters*\n",
        "\n",
        "2. **Is there separation by category?**\n",
        "   - *TODO: Describe if different categories occupy different regions*\n",
        "\n",
        "3. **Why might this happen?**\n",
        "   - *TODO: Explain based on how embeddings capture semantic meaning*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Evaluation Suite\n",
        "\n",
        "We evaluate our retrieval systems using three standard metrics:\n",
        "- **Recall**: Did we find the relevant documents?\n",
        "- **Precision**: Are the retrieved documents relevant?\n",
        "- **MRR (Mean Reciprocal Rank)**: How early do relevant documents appear?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_recall(retrieved_ids, relevant_ids):\n",
        "    \"\"\"\n",
        "    Compute Recall@k.\n",
        "    \n",
        "    Recall = # of relevant documents retrieved / # of total relevant documents\n",
        "    \n",
        "    Answers: Did the system find the documents that matter?\n",
        "    \"\"\"\n",
        "    if len(relevant_ids) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    retrieved_set = set(retrieved_ids)\n",
        "    relevant_set = set(relevant_ids)\n",
        "    \n",
        "    return len(retrieved_set & relevant_set) / len(relevant_set)\n",
        "\n",
        "\n",
        "def compute_precision(retrieved_ids, relevant_ids):\n",
        "    \"\"\"\n",
        "    Compute Precision@k.\n",
        "    \n",
        "    Precision = # of relevant documents retrieved / # of total retrieved documents\n",
        "    \n",
        "    Answers: Are the top results useful?\n",
        "    \"\"\"\n",
        "    if len(retrieved_ids) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    retrieved_set = set(retrieved_ids)\n",
        "    relevant_set = set(relevant_ids)\n",
        "    \n",
        "    return len(retrieved_set & relevant_set) / len(retrieved_ids)\n",
        "\n",
        "\n",
        "def compute_mrr(retrieved_ids, relevant_ids):\n",
        "    \"\"\"\n",
        "    Compute Mean Reciprocal Rank.\n",
        "    \n",
        "    MRR = 1 / rank of first relevant document\n",
        "    \n",
        "    Answers: How early does a relevant document appear?\n",
        "    \"\"\"\n",
        "    relevant_set = set(relevant_ids)\n",
        "    \n",
        "    for rank, doc_id in enumerate(retrieved_ids, start=1):\n",
        "        if doc_id in relevant_set:\n",
        "            return 1.0 / rank\n",
        "    \n",
        "    return 0.0  # No relevant document found\n",
        "\n",
        "\n",
        "print(\"‚úÖ Evaluation functions defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_retrieval(topk_indices, ground_truth, query_ids):\n",
        "    \"\"\"\n",
        "    Evaluate a retrieval method across all queries.\n",
        "    \n",
        "    Returns:\n",
        "        dict with average recall, precision, and MRR\n",
        "    \"\"\"\n",
        "    recalls = []\n",
        "    precisions = []\n",
        "    mrrs = []\n",
        "    \n",
        "    for i, query_id in enumerate(query_ids):\n",
        "        retrieved = topk_indices[i]\n",
        "        relevant = ground_truth.get(query_id, [])\n",
        "        \n",
        "        recalls.append(compute_recall(retrieved, relevant))\n",
        "        precisions.append(compute_precision(retrieved, relevant))\n",
        "        mrrs.append(compute_mrr(retrieved, relevant))\n",
        "    \n",
        "    return {\n",
        "        'Recall@k': np.mean(recalls),\n",
        "        'Precision@k': np.mean(precisions),\n",
        "        'MRR': np.mean(mrrs),\n",
        "        'recalls': recalls,\n",
        "        'precisions': precisions,\n",
        "        'mrrs': mrrs\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Evaluation framework ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate all methods\n",
        "query_ids = df_queries_train['id'].tolist()\n",
        "\n",
        "print(f\"Evaluating retrieval methods (k={K})...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# TF-IDF\n",
        "results_tfidf = evaluate_retrieval(topk_indices_tfidf, ground_truth, query_ids)\n",
        "print(f\"\\nüìä TF-IDF Results:\")\n",
        "print(f\"   Recall@{K}: {results_tfidf['Recall@k']:.4f}\")\n",
        "print(f\"   Precision@{K}: {results_tfidf['Precision@k']:.4f}\")\n",
        "print(f\"   MRR: {results_tfidf['MRR']:.4f}\")\n",
        "\n",
        "# BM25+\n",
        "results_bm25 = evaluate_retrieval(topk_indices_bm25, ground_truth, query_ids)\n",
        "print(f\"\\nüìä BM25+ Results:\")\n",
        "print(f\"   Recall@{K}: {results_bm25['Recall@k']:.4f}\")\n",
        "print(f\"   Precision@{K}: {results_bm25['Precision@k']:.4f}\")\n",
        "print(f\"   MRR: {results_bm25['MRR']:.4f}\")\n",
        "\n",
        "# Embeddings\n",
        "results_emb = evaluate_retrieval(topk_indices_emb, ground_truth, query_ids)\n",
        "print(f\"\\nüìä Embeddings Results:\")\n",
        "print(f\"   Recall@{K}: {results_emb['Recall@k']:.4f}\")\n",
        "print(f\"   Precision@{K}: {results_emb['Precision@k']:.4f}\")\n",
        "print(f\"   MRR: {results_emb['MRR']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Results Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison dataframe\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Method': ['TF-IDF', 'BM25+', 'Embeddings'],\n",
        "    f'Recall@{K}': [\n",
        "        results_tfidf['Recall@k'],\n",
        "        results_bm25['Recall@k'],\n",
        "        results_emb['Recall@k']\n",
        "    ],\n",
        "    f'Precision@{K}': [\n",
        "        results_tfidf['Precision@k'],\n",
        "        results_bm25['Precision@k'],\n",
        "        results_emb['Precision@k']\n",
        "    ],\n",
        "    'MRR': [\n",
        "        results_tfidf['MRR'],\n",
        "        results_bm25['MRR'],\n",
        "        results_emb['MRR']\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä RESULTS COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "display(comparison_df)\n",
        "\n",
        "# Save results\n",
        "comparison_df.to_csv('reports/evaluation_results.csv', index=False)\n",
        "print(\"\\n‚úÖ Results saved to reports/evaluation_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization of results\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "metrics = [f'Recall@{K}', f'Precision@{K}', 'MRR']\n",
        "colors = ['#2ecc71', '#3498db', '#9b59b6']\n",
        "\n",
        "for ax, metric, color in zip(axes, metrics, colors):\n",
        "    values = comparison_df[metric].values\n",
        "    bars = ax.bar(comparison_df['Method'], values, color=color, alpha=0.8)\n",
        "    \n",
        "    # Add value labels\n",
        "    for bar, val in zip(bars, values):\n",
        "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{val:.3f}', ha='center', va='bottom', fontsize=11)\n",
        "    \n",
        "    ax.set_title(metric, fontsize=14, fontweight='bold')\n",
        "    ax.set_ylim(0, max(values) * 1.2)\n",
        "    ax.set_ylabel('Score')\n",
        "\n",
        "plt.suptitle('Retrieval Methods Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig('reports/model_comparison.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Results Analysis\n",
        "\n",
        "**Questions to answer:**\n",
        "\n",
        "1. **Which model performs best overall?**\n",
        "   - *TODO: Compare and discuss*\n",
        "\n",
        "2. **Why might one model outperform others?**\n",
        "   - *TODO: Discuss strengths/weaknesses of each approach*\n",
        "\n",
        "3. **What are the trade-offs?**\n",
        "   - *TODO: Consider speed, accuracy, and resource requirements*\n",
        "\n",
        "4. **How does changing k affect results?**\n",
        "   - *TODO: Experiment and discuss*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Kaggle Submission\n",
        "\n",
        "Generate predictions for the test queries and create submission file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate predictions for test queries using best method\n",
        "# (Choose based on evaluation results)\n",
        "\n",
        "print(\"Generating predictions for test queries...\")\n",
        "\n",
        "# Transform test queries\n",
        "test_query_matrix = tfidf_vectorizer.transform(df_queries_test['content_clean'])\n",
        "\n",
        "# Retrieve (using TF-IDF as example - change to best method)\n",
        "test_topk_indices, test_topk_scores = retrieve_topk_tfidf(\n",
        "    test_query_matrix, tfidf_doc_matrix, doc_ids, k=K\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Generated predictions for {len(test_topk_indices)} test queries\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create submission file\n",
        "submission = {\n",
        "    query_id: retrieved\n",
        "    for query_id, retrieved in zip(df_queries_test['id'].tolist(), test_topk_indices)\n",
        "}\n",
        "\n",
        "# Save\n",
        "with open('submission_phase1.json', 'w') as f:\n",
        "    json.dump(submission, f)\n",
        "\n",
        "print(\"‚úÖ Submission file created: submission_phase1.json\")\n",
        "print(f\"   Total queries: {len(submission)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results for later use\n",
        "results = {\n",
        "    'topk_indices_tfidf': topk_indices_tfidf,\n",
        "    'topk_scores_tfidf': topk_scores_tfidf,\n",
        "    'topk_indices_bm25': topk_indices_bm25,\n",
        "    'topk_scores_bm25': topk_scores_bm25,\n",
        "    'topk_indices_emb': topk_indices_emb,\n",
        "    'topk_scores_emb': topk_scores_emb,\n",
        "    'evaluation_results': {\n",
        "        'tfidf': results_tfidf,\n",
        "        'bm25': results_bm25,\n",
        "        'embeddings': results_emb\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('all_results.pkl', 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "print(\"‚úÖ All results saved to all_results.pkl\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
